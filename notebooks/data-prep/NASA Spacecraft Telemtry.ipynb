{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Spacecraft Telemetry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Final\n",
    "from collections.abc import Callable\n",
    "from config import data_raw_folder, data_processed_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_collection_prefix = \"NASA\"\n",
    "source_folder = os.path.join(data_raw_folder, \"NASA Spacecraft Telemetry Data\")\n",
    "target_folder = data_processed_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "DatasetMetadataRecord = {\n",
    "    \"dataset_name\": str,\n",
    "    \"collection_name\": str,\n",
    "    \"train_path\": str,\n",
    "    \"test_path\": str,\n",
    "    \"dataset_type\": str,\n",
    "    \"datetime_index\": bool,\n",
    "    \"split_at\": int,\n",
    "    \"train_type\": str,\n",
    "    \"train_is_normal\": bool,\n",
    "    \"input_type\": str,\n",
    "    \"length\": int\n",
    "}\n",
    "\n",
    "class DatasetMetadata:\n",
    "    \"\"\"\n",
    "    ATTENTION: Not thread-safe! There is no check for changes to the underlying `dataset.csv` file while this class is loaded.\n",
    "    \"\"\"\n",
    "    \n",
    "    FILENAME: Final[str] = \"datasets.csv\"\n",
    "    \n",
    "    _filepath: str\n",
    "    _df: pd.DataFrame\n",
    "    _dirty: bool\n",
    "\n",
    "    def __init__(self, target_folder: str):\n",
    "        self._filepath = os.path.join(target_folder, self.FILENAME)\n",
    "        self._dirty = False\n",
    "        if not os.path.isfile(self._filepath):\n",
    "            self._df = self._create_metadata_file()\n",
    "        else:\n",
    "            self.refresh(force = True)\n",
    "    \n",
    "    def __enter__(self) -> 'DatasetMetadata':\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exception_type, exception_value, exception_traceback) -> 'DatasetMetadata':\n",
    "        self.save()\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return repr(self._df)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self._df)\n",
    "        \n",
    "    def _create_metadata_file(self) -> pd.DataFrame:\n",
    "        df_temp = pd.DataFrame(columns=[\"dataset_name\", \"collection_name\", \"train_path\", \"test_path\", \"dataset_type\", \"datetime_index\", \"split_at\", \"train_type\", \"train_is_normal\", \"input_type\", \"length\"])\n",
    "        df_temp.set_index([\"dataset_name\", \"collection_name\"], inplace=True)\n",
    "        df_temp.to_csv(self._filepath)\n",
    "        return df_temp\n",
    "    \n",
    "    def add_dataset(self,\n",
    "        dataset_name: str,\n",
    "        collection_name: str,\n",
    "        train_path: str,\n",
    "        test_path: str,\n",
    "        dataset_type: str,\n",
    "        datetime_index: bool,\n",
    "        split_at: int,\n",
    "        train_type: str,\n",
    "        train_is_normal: bool,\n",
    "        input_type: str,\n",
    "        dataset_length: int\n",
    "    ) -> 'DatasetMetadata':\n",
    "        df_new = pd.DataFrame({\n",
    "            \"train_path\": train_path,\n",
    "            \"test_path\": test_path,\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"datetime_index\": datetime_index,\n",
    "            \"split_at\": split_at,\n",
    "            \"train_type\": train_type,\n",
    "            \"train_is_normal\": train_is_normal,\n",
    "            \"input_type\": input_type,\n",
    "            \"length\": dataset_length\n",
    "        }, index=[(dataset_name, collection_name)])\n",
    "        df = pd.concat([self._df, df_new], axis=0)\n",
    "        df = df[~df.index.duplicated(keep = \"last\")]\n",
    "        self._df = df\n",
    "        self._dirty = True\n",
    "        return self\n",
    "    \n",
    "    def add_datasets(self, datasets: list[DatasetMetadataRecord]) -> 'DatasetMetadata':\n",
    "        df_new = pd.DataFrame(datasets)\n",
    "        df_new.set_index([\"dataset_name\", \"collection_name\"], inplace = True)\n",
    "        df = pd.concat([self._df, df_new], axis=0)\n",
    "        df = df[~df.index.duplicated(keep = \"last\")]\n",
    "        self._df = df\n",
    "        self._dirty = True\n",
    "        return self\n",
    "    \n",
    "    def refresh(self, force: bool = False) -> None:\n",
    "        if not force and self._dirty:\n",
    "            raise Exception(\"There are unsaved changes in memory that would get lost by reading from disk again!\")\n",
    "        else:\n",
    "            self._df = pd.read_csv(self._filepath, index_col=[\"dataset_name\", \"collection_name\"])\n",
    "    \n",
    "    def save(self) -> None:\n",
    "        self._df.to_csv(self._filepath)\n",
    "        self._dirty = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_subfolder(input_type: str, dataset_collection_name: str) -> str:\n",
    "    dataset_subfolder = os.path.join(target_folder, input_type, dataset_collection_name)\n",
    "    try:\n",
    "        os.makedirs(dataset_subfolder)\n",
    "        print(f\"Created directories {dataset_subfolder}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directories {dataset_subfolder} already exist\")\n",
    "        pass\n",
    "    return dataset_subfolder\n",
    "\n",
    "def transform_and_label(source: str, target: str, anomaly_windows: list[str], force_all_normal: bool = False) -> None:\n",
    "    df = pd.DataFrame(np.load(source)[:,1], columns=[\"value\"])\n",
    "    df.index.name = \"timestamp\"\n",
    "    df = df[[\"value\"]]\n",
    "    df[\"is_anomaly\"] = 0\n",
    "\n",
    "    if not force_all_normal:\n",
    "        for t1, t2 in anomaly_windows:\n",
    "            tmp = df[df.index >= t1]\n",
    "            tmp = tmp[tmp.index <= t2]\n",
    "            df[\"is_anomaly\"].values[tmp.index] = 1\n",
    "\n",
    "    df.to_csv(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared by all datasets\n",
    "dataset_type = \"real\"\n",
    "input_type = \"univariate\"\n",
    "datetime_index = False\n",
    "train_type = \"semi-supervised\"\n",
    "train_is_normal = True\n",
    "\n",
    "dm = DatasetMetadata(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-1.npy -> data-processed/univariate/NASA-SMAP/P-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-1.npy -> data-processed/univariate/NASA-SMAP/P-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/S-1.npy -> data-processed/univariate/NASA-SMAP/S-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/S-1.npy -> data-processed/univariate/NASA-SMAP/S-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-1.npy -> data-processed/univariate/NASA-SMAP/E-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-1.npy -> data-processed/univariate/NASA-SMAP/E-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-2.npy -> data-processed/univariate/NASA-SMAP/E-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-2.npy -> data-processed/univariate/NASA-SMAP/E-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-3.npy -> data-processed/univariate/NASA-SMAP/E-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-3.npy -> data-processed/univariate/NASA-SMAP/E-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-4.npy -> data-processed/univariate/NASA-SMAP/E-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-4.npy -> data-processed/univariate/NASA-SMAP/E-4.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-5.npy -> data-processed/univariate/NASA-SMAP/E-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-5.npy -> data-processed/univariate/NASA-SMAP/E-5.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-6.npy -> data-processed/univariate/NASA-SMAP/E-6.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-6.npy -> data-processed/univariate/NASA-SMAP/E-6.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-7.npy -> data-processed/univariate/NASA-SMAP/E-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-7.npy -> data-processed/univariate/NASA-SMAP/E-7.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-8.npy -> data-processed/univariate/NASA-SMAP/E-8.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-8.npy -> data-processed/univariate/NASA-SMAP/E-8.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-9.npy -> data-processed/univariate/NASA-SMAP/E-9.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-9.npy -> data-processed/univariate/NASA-SMAP/E-9.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-10.npy -> data-processed/univariate/NASA-SMAP/E-10.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-10.npy -> data-processed/univariate/NASA-SMAP/E-10.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-11.npy -> data-processed/univariate/NASA-SMAP/E-11.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-11.npy -> data-processed/univariate/NASA-SMAP/E-11.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-12.npy -> data-processed/univariate/NASA-SMAP/E-12.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-12.npy -> data-processed/univariate/NASA-SMAP/E-12.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/E-13.npy -> data-processed/univariate/NASA-SMAP/E-13.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/E-13.npy -> data-processed/univariate/NASA-SMAP/E-13.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-1.npy -> data-processed/univariate/NASA-SMAP/A-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-1.npy -> data-processed/univariate/NASA-SMAP/A-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-1.npy -> data-processed/univariate/NASA-SMAP/D-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-1.npy -> data-processed/univariate/NASA-SMAP/D-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-2.npy -> data-processed/univariate/NASA-SMAP/P-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-2.npy -> data-processed/univariate/NASA-SMAP/P-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-3.npy -> data-processed/univariate/NASA-SMAP/P-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-3.npy -> data-processed/univariate/NASA-SMAP/P-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-2.npy -> data-processed/univariate/NASA-SMAP/D-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-2.npy -> data-processed/univariate/NASA-SMAP/D-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-3.npy -> data-processed/univariate/NASA-SMAP/D-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-3.npy -> data-processed/univariate/NASA-SMAP/D-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-4.npy -> data-processed/univariate/NASA-SMAP/D-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-4.npy -> data-processed/univariate/NASA-SMAP/D-4.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-2.npy -> data-processed/univariate/NASA-SMAP/A-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-2.npy -> data-processed/univariate/NASA-SMAP/A-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-3.npy -> data-processed/univariate/NASA-SMAP/A-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-3.npy -> data-processed/univariate/NASA-SMAP/A-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-4.npy -> data-processed/univariate/NASA-SMAP/A-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-4.npy -> data-processed/univariate/NASA-SMAP/A-4.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-1.npy -> data-processed/univariate/NASA-SMAP/G-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-1.npy -> data-processed/univariate/NASA-SMAP/G-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-2.npy -> data-processed/univariate/NASA-SMAP/G-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-2.npy -> data-processed/univariate/NASA-SMAP/G-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-5.npy -> data-processed/univariate/NASA-SMAP/D-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-5.npy -> data-processed/univariate/NASA-SMAP/D-5.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-6.npy -> data-processed/univariate/NASA-SMAP/D-6.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-6.npy -> data-processed/univariate/NASA-SMAP/D-6.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-7.npy -> data-processed/univariate/NASA-SMAP/D-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-7.npy -> data-processed/univariate/NASA-SMAP/D-7.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-1.npy -> data-processed/univariate/NASA-SMAP/F-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-1.npy -> data-processed/univariate/NASA-SMAP/F-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-4.npy -> data-processed/univariate/NASA-SMAP/P-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-4.npy -> data-processed/univariate/NASA-SMAP/P-4.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-3.npy -> data-processed/univariate/NASA-SMAP/G-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-3.npy -> data-processed/univariate/NASA-SMAP/G-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-1.npy -> data-processed/univariate/NASA-SMAP/T-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-1.npy -> data-processed/univariate/NASA-SMAP/T-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-2.npy -> data-processed/univariate/NASA-SMAP/T-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-2.npy -> data-processed/univariate/NASA-SMAP/T-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-8.npy -> data-processed/univariate/NASA-SMAP/D-8.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-8.npy -> data-processed/univariate/NASA-SMAP/D-8.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-9.npy -> data-processed/univariate/NASA-SMAP/D-9.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-9.npy -> data-processed/univariate/NASA-SMAP/D-9.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-2.npy -> data-processed/univariate/NASA-SMAP/F-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-2.npy -> data-processed/univariate/NASA-SMAP/F-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-4.npy -> data-processed/univariate/NASA-SMAP/G-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-4.npy -> data-processed/univariate/NASA-SMAP/G-4.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-3.npy -> data-processed/univariate/NASA-SMAP/T-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-3.npy -> data-processed/univariate/NASA-SMAP/T-3.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-11.npy -> data-processed/univariate/NASA-SMAP/D-11.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-11.npy -> data-processed/univariate/NASA-SMAP/D-11.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-12.npy -> data-processed/univariate/NASA-SMAP/D-12.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-12.npy -> data-processed/univariate/NASA-SMAP/D-12.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/B-1.npy -> data-processed/univariate/NASA-SMAP/B-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/B-1.npy -> data-processed/univariate/NASA-SMAP/B-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-6.npy -> data-processed/univariate/NASA-SMAP/G-6.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-6.npy -> data-processed/univariate/NASA-SMAP/G-6.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/G-7.npy -> data-processed/univariate/NASA-SMAP/G-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/G-7.npy -> data-processed/univariate/NASA-SMAP/G-7.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-7.npy -> data-processed/univariate/NASA-SMAP/P-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-7.npy -> data-processed/univariate/NASA-SMAP/P-7.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/R-1.npy -> data-processed/univariate/NASA-SMAP/R-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/R-1.npy -> data-processed/univariate/NASA-SMAP/R-1.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-5.npy -> data-processed/univariate/NASA-SMAP/A-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-5.npy -> data-processed/univariate/NASA-SMAP/A-5.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-6.npy -> data-processed/univariate/NASA-SMAP/A-6.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-6.npy -> data-processed/univariate/NASA-SMAP/A-6.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-7.npy -> data-processed/univariate/NASA-SMAP/A-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-7.npy -> data-processed/univariate/NASA-SMAP/A-7.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-13.npy -> data-processed/univariate/NASA-SMAP/D-13.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-13.npy -> data-processed/univariate/NASA-SMAP/D-13.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-2.npy -> data-processed/univariate/NASA-SMAP/P-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-2.npy -> data-processed/univariate/NASA-SMAP/P-2.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-8.npy -> data-processed/univariate/NASA-SMAP/A-8.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-8.npy -> data-processed/univariate/NASA-SMAP/A-8.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/A-9.npy -> data-processed/univariate/NASA-SMAP/A-9.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/A-9.npy -> data-processed/univariate/NASA-SMAP/A-9.test.csv\n",
      "Directories data-processed/univariate/NASA-SMAP already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-3.npy -> data-processed/univariate/NASA-SMAP/F-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-3.npy -> data-processed/univariate/NASA-SMAP/F-3.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-6.npy -> data-processed/univariate/NASA-MSL/M-6.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-6.npy -> data-processed/univariate/NASA-MSL/M-6.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-1.npy -> data-processed/univariate/NASA-MSL/M-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-1.npy -> data-processed/univariate/NASA-MSL/M-1.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-2.npy -> data-processed/univariate/NASA-MSL/M-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-2.npy -> data-processed/univariate/NASA-MSL/M-2.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/S-2.npy -> data-processed/univariate/NASA-MSL/S-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/S-2.npy -> data-processed/univariate/NASA-MSL/S-2.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-10.npy -> data-processed/univariate/NASA-MSL/P-10.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-10.npy -> data-processed/univariate/NASA-MSL/P-10.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-4.npy -> data-processed/univariate/NASA-MSL/T-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-4.npy -> data-processed/univariate/NASA-MSL/T-4.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-5.npy -> data-processed/univariate/NASA-MSL/T-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-5.npy -> data-processed/univariate/NASA-MSL/T-5.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-7.npy -> data-processed/univariate/NASA-MSL/F-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-7.npy -> data-processed/univariate/NASA-MSL/F-7.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-3.npy -> data-processed/univariate/NASA-MSL/M-3.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-3.npy -> data-processed/univariate/NASA-MSL/M-3.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-4.npy -> data-processed/univariate/NASA-MSL/M-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-4.npy -> data-processed/univariate/NASA-MSL/M-4.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-5.npy -> data-processed/univariate/NASA-MSL/M-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-5.npy -> data-processed/univariate/NASA-MSL/M-5.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-15.npy -> data-processed/univariate/NASA-MSL/P-15.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-15.npy -> data-processed/univariate/NASA-MSL/P-15.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/C-1.npy -> data-processed/univariate/NASA-MSL/C-1.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/C-1.npy -> data-processed/univariate/NASA-MSL/C-1.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/C-2.npy -> data-processed/univariate/NASA-MSL/C-2.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/C-2.npy -> data-processed/univariate/NASA-MSL/C-2.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-12.npy -> data-processed/univariate/NASA-MSL/T-12.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-12.npy -> data-processed/univariate/NASA-MSL/T-12.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-13.npy -> data-processed/univariate/NASA-MSL/T-13.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-13.npy -> data-processed/univariate/NASA-MSL/T-13.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-4.npy -> data-processed/univariate/NASA-MSL/F-4.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-4.npy -> data-processed/univariate/NASA-MSL/F-4.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-5.npy -> data-processed/univariate/NASA-MSL/F-5.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-5.npy -> data-processed/univariate/NASA-MSL/F-5.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-14.npy -> data-processed/univariate/NASA-MSL/D-14.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-14.npy -> data-processed/univariate/NASA-MSL/D-14.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-9.npy -> data-processed/univariate/NASA-MSL/T-9.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-9.npy -> data-processed/univariate/NASA-MSL/T-9.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-14.npy -> data-processed/univariate/NASA-MSL/P-14.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-14.npy -> data-processed/univariate/NASA-MSL/P-14.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/T-8.npy -> data-processed/univariate/NASA-MSL/T-8.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/T-8.npy -> data-processed/univariate/NASA-MSL/T-8.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/P-11.npy -> data-processed/univariate/NASA-MSL/P-11.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/P-11.npy -> data-processed/univariate/NASA-MSL/P-11.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-15.npy -> data-processed/univariate/NASA-MSL/D-15.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-15.npy -> data-processed/univariate/NASA-MSL/D-15.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/D-16.npy -> data-processed/univariate/NASA-MSL/D-16.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/D-16.npy -> data-processed/univariate/NASA-MSL/D-16.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/M-7.npy -> data-processed/univariate/NASA-MSL/M-7.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/M-7.npy -> data-processed/univariate/NASA-MSL/M-7.test.csv\n",
      "Directories data-processed/univariate/NASA-MSL already exist\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/train/F-8.npy -> data-processed/univariate/NASA-MSL/F-8.train.csv\n",
      "Processed source dataset data-raw/NASA Spacecraft Telemetry Data/test/F-8.npy -> data-processed/univariate/NASA-MSL/F-8.test.csv\n"
     ]
    }
   ],
   "source": [
    "# dataset transformation\n",
    "transform_file: Callable[[str, str, list[str], bool], None] = transform_and_label\n",
    "\n",
    "meta = pd.read_csv(os.path.join(source_folder, \"labeled_anomalies.csv\"))\n",
    "json.loads(meta[\"anomaly_sequences\"][0])\n",
    "\n",
    "for _, dataset in meta.iterrows():\n",
    "    \n",
    "    dataset_name = dataset[\"chan_id\"]\n",
    "    collection_name = dataset_collection_prefix + \"-\" + dataset[\"spacecraft\"]\n",
    "    dataset_length = dataset[\"num_values\"]\n",
    "    dataset_subfolder = create_target_subfolder(input_type, collection_name)\n",
    "    \n",
    "    windows = json.loads(dataset[\"anomaly_sequences\"])\n",
    "    \n",
    "    paths = {}\n",
    "    for t_type in [\"train\", \"test\"]:\n",
    "        source_file = os.path.join(source_folder, t_type, dataset_name + \".npy\")\n",
    "        filename = f\"{dataset_name}.{t_type}.csv\"\n",
    "        path = os.path.join(dataset_subfolder, filename)\n",
    "        paths[t_type] = path\n",
    "        \n",
    "        # transform file\n",
    "        transform_file(source_file, path, windows, force_all_normal=(t_type == \"train\"))\n",
    "        print(f\"Processed source dataset {source_file} -> {path}\")\n",
    "\n",
    "    # save metadata\n",
    "    dm.add_dataset(\n",
    "        dataset_name = dataset_name,\n",
    "        collection_name = collection_name,\n",
    "        train_path = paths[\"train\"],\n",
    "        test_path = paths[\"test\"],\n",
    "        dataset_type = dataset_type,\n",
    "        datetime_index = datetime_index,\n",
    "        split_at = None,\n",
    "        train_type = train_type,\n",
    "        train_is_normal = train_is_normal,\n",
    "        input_type = input_type,\n",
    "        dataset_length = dataset_length\n",
    "    )\n",
    "\n",
    "# save metadata of benchmark\n",
    "dm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_path</th>\n",
       "      <th>test_path</th>\n",
       "      <th>type</th>\n",
       "      <th>datetime_index</th>\n",
       "      <th>split_at</th>\n",
       "      <th>train_type</th>\n",
       "      <th>train_is_normal</th>\n",
       "      <th>input_type</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th>collection_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1Benchmark-6</th>\n",
       "      <th>WebscopeS5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data-processed/univariate/WebscopeS5/A1Benchma...</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>False</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Benchmark-3</th>\n",
       "      <th>WebscopeS5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data-processed/univariate/WebscopeS5/A1Benchma...</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>False</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Benchmark-40</th>\n",
       "      <th>WebscopeS5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data-processed/univariate/WebscopeS5/A1Benchma...</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>False</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Benchmark-20</th>\n",
       "      <th>WebscopeS5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data-processed/univariate/WebscopeS5/A1Benchma...</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>False</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Benchmark-4</th>\n",
       "      <th>WebscopeS5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data-processed/univariate/WebscopeS5/A1Benchma...</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>False</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-11</th>\n",
       "      <th>NASA-MSL</th>\n",
       "      <td>data-processed/univariate/NASA-MSL/P-11.train.csv</td>\n",
       "      <td>data-processed/univariate/NASA-MSL/P-11.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-15</th>\n",
       "      <th>NASA-MSL</th>\n",
       "      <td>data-processed/univariate/NASA-MSL/D-15.train.csv</td>\n",
       "      <td>data-processed/univariate/NASA-MSL/D-15.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-16</th>\n",
       "      <th>NASA-MSL</th>\n",
       "      <td>data-processed/univariate/NASA-MSL/D-16.train.csv</td>\n",
       "      <td>data-processed/univariate/NASA-MSL/D-16.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>2191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-7</th>\n",
       "      <th>NASA-MSL</th>\n",
       "      <td>data-processed/univariate/NASA-MSL/M-7.train.csv</td>\n",
       "      <td>data-processed/univariate/NASA-MSL/M-7.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>2156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-8</th>\n",
       "      <th>NASA-MSL</th>\n",
       "      <td>data-processed/univariate/NASA-MSL/F-8.train.csv</td>\n",
       "      <td>data-processed/univariate/NASA-MSL/F-8.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>2487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       train_path  \\\n",
       "dataset_name   collection_name                                                      \n",
       "A1Benchmark-6  WebscopeS5                                                     NaN   \n",
       "A1Benchmark-3  WebscopeS5                                                     NaN   \n",
       "A1Benchmark-40 WebscopeS5                                                     NaN   \n",
       "A1Benchmark-20 WebscopeS5                                                     NaN   \n",
       "A1Benchmark-4  WebscopeS5                                                     NaN   \n",
       "...                                                                           ...   \n",
       "P-11           NASA-MSL         data-processed/univariate/NASA-MSL/P-11.train.csv   \n",
       "D-15           NASA-MSL         data-processed/univariate/NASA-MSL/D-15.train.csv   \n",
       "D-16           NASA-MSL         data-processed/univariate/NASA-MSL/D-16.train.csv   \n",
       "M-7            NASA-MSL          data-processed/univariate/NASA-MSL/M-7.train.csv   \n",
       "F-8            NASA-MSL          data-processed/univariate/NASA-MSL/F-8.train.csv   \n",
       "\n",
       "                                                                        test_path  \\\n",
       "dataset_name   collection_name                                                      \n",
       "A1Benchmark-6  WebscopeS5       data-processed/univariate/WebscopeS5/A1Benchma...   \n",
       "A1Benchmark-3  WebscopeS5       data-processed/univariate/WebscopeS5/A1Benchma...   \n",
       "A1Benchmark-40 WebscopeS5       data-processed/univariate/WebscopeS5/A1Benchma...   \n",
       "A1Benchmark-20 WebscopeS5       data-processed/univariate/WebscopeS5/A1Benchma...   \n",
       "A1Benchmark-4  WebscopeS5       data-processed/univariate/WebscopeS5/A1Benchma...   \n",
       "...                                                                           ...   \n",
       "P-11           NASA-MSL          data-processed/univariate/NASA-MSL/P-11.test.csv   \n",
       "D-15           NASA-MSL          data-processed/univariate/NASA-MSL/D-15.test.csv   \n",
       "D-16           NASA-MSL          data-processed/univariate/NASA-MSL/D-16.test.csv   \n",
       "M-7            NASA-MSL           data-processed/univariate/NASA-MSL/M-7.test.csv   \n",
       "F-8            NASA-MSL           data-processed/univariate/NASA-MSL/F-8.test.csv   \n",
       "\n",
       "                                type  datetime_index  split_at  \\\n",
       "dataset_name   collection_name                                   \n",
       "A1Benchmark-6  WebscopeS5       real            True       NaN   \n",
       "A1Benchmark-3  WebscopeS5       real            True       NaN   \n",
       "A1Benchmark-40 WebscopeS5       real            True       NaN   \n",
       "A1Benchmark-20 WebscopeS5       real            True       NaN   \n",
       "A1Benchmark-4  WebscopeS5       real            True       NaN   \n",
       "...                              ...             ...       ...   \n",
       "P-11           NASA-MSL         real           False       NaN   \n",
       "D-15           NASA-MSL         real           False       NaN   \n",
       "D-16           NASA-MSL         real           False       NaN   \n",
       "M-7            NASA-MSL         real           False       NaN   \n",
       "F-8            NASA-MSL         real           False       NaN   \n",
       "\n",
       "                                     train_type  train_is_normal  input_type  \\\n",
       "dataset_name   collection_name                                                 \n",
       "A1Benchmark-6  WebscopeS5          unsupervised            False  univariate   \n",
       "A1Benchmark-3  WebscopeS5          unsupervised            False  univariate   \n",
       "A1Benchmark-40 WebscopeS5          unsupervised            False  univariate   \n",
       "A1Benchmark-20 WebscopeS5          unsupervised            False  univariate   \n",
       "A1Benchmark-4  WebscopeS5          unsupervised            False  univariate   \n",
       "...                                         ...              ...         ...   \n",
       "P-11           NASA-MSL         semi-supervised             True  univariate   \n",
       "D-15           NASA-MSL         semi-supervised             True  univariate   \n",
       "D-16           NASA-MSL         semi-supervised             True  univariate   \n",
       "M-7            NASA-MSL         semi-supervised             True  univariate   \n",
       "F-8            NASA-MSL         semi-supervised             True  univariate   \n",
       "\n",
       "                                length  \n",
       "dataset_name   collection_name          \n",
       "A1Benchmark-6  WebscopeS5         1439  \n",
       "A1Benchmark-3  WebscopeS5         1461  \n",
       "A1Benchmark-40 WebscopeS5         1427  \n",
       "A1Benchmark-20 WebscopeS5         1422  \n",
       "A1Benchmark-4  WebscopeS5         1423  \n",
       "...                                ...  \n",
       "P-11           NASA-MSL           3535  \n",
       "D-15           NASA-MSL           2158  \n",
       "D-16           NASA-MSL           2191  \n",
       "M-7            NASA-MSL           2156  \n",
       "F-8            NASA-MSL           2487  \n",
       "\n",
       "[638 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.refresh()\n",
    "dm._df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chan_id                                                     P-1\n",
      "spacecraft                                                 SMAP\n",
      "anomaly_sequences    [[2149, 2349], [4536, 4844], [3539, 3779]]\n",
      "class                      [contextual, contextual, contextual]\n",
      "num_values                                                 8505\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(os.path.join(source_folder, \"labeled_anomalies.csv\"))\n",
    "json.loads(meta[\"anomaly_sequences\"][0])\n",
    "dataset = next(meta.iterrows())[1]\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data-raw/NASA Spacecraft Telemetry Data/test/P-1.npy\n",
      "[[2149, 2349], [4536, 4844], [3539, 3779]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.695162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.685704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.725719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.761368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.745362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>0.293561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8501</th>\n",
       "      <td>0.341579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502</th>\n",
       "      <td>-0.316115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>-0.297199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>-0.732266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8505 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              value  is_anomaly\n",
       "timestamp                      \n",
       "0         -0.695162           0\n",
       "1         -0.685704           0\n",
       "2         -0.725719           0\n",
       "3         -0.761368           0\n",
       "4         -0.745362           0\n",
       "...             ...         ...\n",
       "8500       0.293561           0\n",
       "8501       0.341579           0\n",
       "8502      -0.316115           0\n",
       "8503      -0.297199           0\n",
       "8504      -0.732266           0\n",
       "\n",
       "[8505 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"value\"] + [\"C\" + str(i) for i in range(24)]\n",
    "filename = os.path.join(source_folder, \"test\", dataset[\"chan_id\"] + \".npy\")\n",
    "print(f\"loading {filename}\")\n",
    "dd = np.load(filename)\n",
    "df = pd.DataFrame(dd, columns=columns)\n",
    "df.index.name = \"timestamp\"\n",
    "df = df[[\"value\"]]\n",
    "df[\"is_anomaly\"] = 0\n",
    "\n",
    "windows = json.loads(dataset[\"anomaly_sequences\"])\n",
    "\n",
    "for t1, t2 in windows:\n",
    "    tmp = df[df.index >= t1]\n",
    "    tmp = tmp[tmp.index <= t2]\n",
    "    df[\"is_anomaly\"].values[tmp.index] = 1\n",
    "\n",
    "print(windows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 751)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = os.path.join(source_folder, \"train\", dataset[\"chan_id\"] + \".npy\")\n",
    "testfile = os.path.join(source_folder, \"test\", dataset[\"chan_id\"] + \".npy\")\n",
    "windows = json.loads(dataset[\"anomaly_sequences\"])\n",
    "\n",
    "transform_and_label(trainfile, \"P-1.train.csv\", windows, force_all_normal=True)\n",
    "transform_and_label(testfile, \"P-1.test.csv\", windows, force_all_normal=False)\n",
    "\n",
    "df = pd.read_csv(\"P-1.train.csv\", index_col=\"timestamp\")\n",
    "anomalies_in_train = len(df[df[\"is_anomaly\"] == 1])\n",
    "df = pd.read_csv(\"P-1.test.csv\", index_col=\"timestamp\")\n",
    "anomalies_in_test = len(df[df[\"is_anomaly\"] == 1])\n",
    "(anomalies_in_train, anomalies_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>2154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2158 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  value  is_anomaly\n",
       "0             0    0.0           0\n",
       "1             1    0.0           0\n",
       "2             2    0.0           0\n",
       "3             3    0.0           0\n",
       "4             4    0.0           0\n",
       "...         ...    ...         ...\n",
       "2153       2153    0.0           0\n",
       "2154       2154    0.0           0\n",
       "2155       2155    0.0           0\n",
       "2156       2156    0.0           0\n",
       "2157       2157    0.0           0\n",
       "\n",
       "[2158 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-processed/univariate/NASA-MSL/C-1.train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"data-raw/NASA Spacecraft Telemetry Data/train/P-1.npy\")[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
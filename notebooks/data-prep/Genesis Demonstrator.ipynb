{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genesis Demonstrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Final\n",
    "from config import data_raw_folder, data_processed_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_collection_name = \"Genesis\"\n",
    "source_folder = os.path.join(data_raw_folder, \"genesis-demonstrator/data\")\n",
    "target_folder = data_processed_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "DatasetMetadataRecord = {\n",
    "    \"collection_name\": str,\n",
    "    \"dataset_name\": str,\n",
    "    \"train_path\": str,\n",
    "    \"test_path\": str,\n",
    "    \"dataset_type\": str,\n",
    "    \"datetime_index\": bool,\n",
    "    \"split_at\": int,\n",
    "    \"train_type\": str,\n",
    "    \"train_is_normal\": bool,\n",
    "    \"input_type\": str,\n",
    "    \"length\": int\n",
    "}\n",
    "\n",
    "class DatasetMetadata:\n",
    "    \"\"\"\n",
    "    ATTENTION: Not thread-safe! There is no check for changes to the underlying `dataset.csv` file while this class is loaded.\n",
    "    \"\"\"\n",
    "    \n",
    "    FILENAME: Final[str] = \"datasets.csv\"\n",
    "    \n",
    "    _filepath: str\n",
    "    _df: pd.DataFrame\n",
    "    _dirty: bool\n",
    "\n",
    "    def __init__(self, target_folder: str):\n",
    "        self._filepath = os.path.join(target_folder, self.FILENAME)\n",
    "        self._dirty = False\n",
    "        if not os.path.isfile(self._filepath):\n",
    "            self._df = self._create_metadata_file()\n",
    "        else:\n",
    "            self.refresh(force = True)\n",
    "    \n",
    "    def __enter__(self) -> 'DatasetMetadata':\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exception_type, exception_value, exception_traceback) -> 'DatasetMetadata':\n",
    "        self.save()\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return repr(self._df)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self._df)\n",
    "        \n",
    "    def _create_metadata_file(self) -> pd.DataFrame:\n",
    "        df_temp = pd.DataFrame(columns=[\"dataset_name\", \"collection_name\", \"train_path\", \"test_path\", \"type\", \"datetime_index\", \"split_at\", \"train_type\", \"train_is_normal\", \"input_type\", \"length\"])\n",
    "        df_temp.set_index([\"collection_name\", \"dataset_name\"], inplace=True)\n",
    "        dir = os.path.dirname(self._filepath)\n",
    "        if not os.path.exists(dir):\n",
    "            print(f\"Directory {dir} does not exist, creating it!\")\n",
    "            os.mkdir(dir)\n",
    "        df_temp.to_csv(self._filepath)\n",
    "        return df_temp\n",
    "    \n",
    "    def add_dataset(self,\n",
    "        dataset_name: str,\n",
    "        collection_name: str,\n",
    "        train_path: str,\n",
    "        test_path: str,\n",
    "        dataset_type: str,\n",
    "        datetime_index: bool,\n",
    "        split_at: int,\n",
    "        train_type: str,\n",
    "        train_is_normal: bool,\n",
    "        input_type: str,\n",
    "        dataset_length: int\n",
    "    ) -> None:\n",
    "        df_new = pd.DataFrame({\n",
    "            \"train_path\": train_path,\n",
    "            \"test_path\": test_path,\n",
    "            \"type\": dataset_type,\n",
    "            \"datetime_index\": datetime_index,\n",
    "            \"split_at\": split_at,\n",
    "            \"train_type\": train_type,\n",
    "            \"train_is_normal\": train_is_normal,\n",
    "            \"input_type\": input_type,\n",
    "            \"length\": dataset_length\n",
    "        }, index=[(dataset_collection_name, dataset_name)])\n",
    "        df = pd.concat([self._df, df_new], axis=0)\n",
    "        df = df[~df.index.duplicated(keep = \"last\")]\n",
    "        self._df = df\n",
    "        self._dirty = True\n",
    "    \n",
    "    def add_datasets(self, datasets: list[DatasetMetadataRecord]) -> None:\n",
    "        df_new = pd.DataFrame(datasets)\n",
    "        df_new.set_index([\"collection_name\", \"dataset_name\"], inplace = True)\n",
    "        df = pd.concat([self._df, df_new], axis=0)\n",
    "        df = df[~df.index.duplicated(keep = \"last\")]\n",
    "        self._df = df\n",
    "        self._dirty = True\n",
    "    \n",
    "    def refresh(self, force: bool = False) -> None:\n",
    "        if not force and self._dirty:\n",
    "            raise Exception(\"There are unsaved changes in memory that would get lost by reading from disk again!\")\n",
    "        else:\n",
    "            self._df = pd.read_csv(self._filepath, index_col=[\"collection_name\", \"dataset_name\"])\n",
    "    \n",
    "    def save(self) -> None:\n",
    "        self._df.to_csv(self._filepath)\n",
    "        self._dirty = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset transformation and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories ../../../data/benchmark-data/data-processed/multivariate/Genesis already exist\n"
     ]
    }
   ],
   "source": [
    "train_type = \"unsupervised\"\n",
    "train_is_normal = False\n",
    "input_type = \"multivariate\"\n",
    "datetime_index = True\n",
    "dataset_type = \"real\"\n",
    "\n",
    "# create target directory\n",
    "dataset_subfolder = os.path.join(target_folder, input_type, dataset_collection_name)\n",
    "try:\n",
    "    os.makedirs(dataset_subfolder)\n",
    "    print(f\"Created directories {dataset_subfolder}\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directories {dataset_subfolder} already exist\")\n",
    "    pass\n",
    "\n",
    "dm = DatasetMetadata(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed source dataset ../../../data/benchmark-data/data-raw/genesis-demonstrator/data/Genesis_AnomalyLabels.csv -> ../../../data/benchmark-data/data-processed/multivariate/Genesis/genesis-anomalies.test.csv\n"
     ]
    }
   ],
   "source": [
    "# get target filenames\n",
    "dataset_name = \"genesis-anomalies\"\n",
    "filename = f\"{dataset_name}.test.csv\"\n",
    "\n",
    "source_file = os.path.join(source_folder, \"Genesis_AnomalyLabels.csv\")\n",
    "path = os.path.join(dataset_subfolder, filename)\n",
    "\n",
    "# transform file\n",
    "df = pd.read_csv(source_file)\n",
    "#df = df.rename(columns={\"Timestamp\": \"timestamp\"})\n",
    "df.insert(len(df.columns), \"is_anomaly\", df.loc[:, \"Label\"])\n",
    "df.insert(1, \"timestamp\", pd.to_datetime(df[\"Timestamp\"], unit='s'))\n",
    "df = df.drop(columns=[\"Timestamp\", \"Label\"])\n",
    "df.to_csv(path, index=False)\n",
    "print(f\"Processed source dataset {source_file} -> {path}\")\n",
    "\n",
    "dataset_length = len(df)\n",
    "\n",
    "# save metadata\n",
    "dm.add_dataset(\n",
    "    dataset_name = dataset_name,\n",
    "    collection_name = dataset_collection_name,\n",
    "    train_path = None,\n",
    "    test_path = path,\n",
    "    dataset_type = dataset_type,\n",
    "    datetime_index = datetime_index,\n",
    "    split_at = None,\n",
    "    train_type = train_type,\n",
    "    train_is_normal = train_is_normal,\n",
    "    input_type = input_type,\n",
    "    dataset_length = dataset_length\n",
    ")\n",
    "\n",
    "dm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                   train_path  \\\ndataset_name                    \ngenesis-anomalies         NaN   \n\n                                                           test_path  type  \\\ndataset_name                                                                 \ngenesis-anomalies  ../../../data/benchmark-data/data-processed/mu...  real   \n\n                   datetime_index  split_at    train_type  train_is_normal  \\\ndataset_name                                                                 \ngenesis-anomalies            True       NaN  unsupervised            False   \n\n                     input_type  length  \ndataset_name                             \ngenesis-anomalies  multivariate   16220  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_path</th>\n      <th>test_path</th>\n      <th>type</th>\n      <th>datetime_index</th>\n      <th>split_at</th>\n      <th>train_type</th>\n      <th>train_is_normal</th>\n      <th>input_type</th>\n      <th>length</th>\n    </tr>\n    <tr>\n      <th>dataset_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>genesis-anomalies</th>\n      <td>NaN</td>\n      <td>../../../data/benchmark-data/data-processed/mu...</td>\n      <td>real</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>unsupervised</td>\n      <td>False</td>\n      <td>multivariate</td>\n      <td>16220</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.refresh()\n",
    "dm._df.loc[\"Genesis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}